{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truy cập vào master của cụm tại địa chỉ 172.19.0.4:7077 với tên chương trình là Stock_price_analysis\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Gold0\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = spark.read.format(\"csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"./newPrices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- US_dollar: string (nullable = true)\n",
      " |-- Euro: string (nullable = true)\n",
      " |-- Japanese_yen: string (nullable = true)\n",
      " |-- Vietnamese_dong: string (nullable = true)\n",
      " |-- Korean_won: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+------------+---------------+----------+\n",
      "|      Date|US_dollar| Euro|Japanese_yen|Vietnamese_dong|Korean_won|\n",
      "+----------+---------+-----+------------+---------------+----------+\n",
      "|12/29/1978|      226|137.1|        #N/A|           #N/A|      #N/A|\n",
      "|  1/1/1979|      226|137.1|        #N/A|           #N/A|      #N/A|\n",
      "|  1/2/1979|    226.8|137.3|   43,164.90|           #N/A|107,470.00|\n",
      "|  1/3/1979|    218.6|  134|   43,717.90|           #N/A|108,027.40|\n",
      "|  1/4/1979|    223.2|136.8|   43,674.90|           #N/A|108,602.50|\n",
      "|  1/5/1979|    225.5|138.4|   44,582.50|           #N/A|110,510.40|\n",
      "|  1/8/1979|    223.1|136.4|   44,436.20|           #N/A|110,356.30|\n",
      "|  1/9/1979|      224|137.3|   44,045.60|           #N/A|109,248.40|\n",
      "| 1/10/1979|    220.7|135.5|   43,366.40|           #N/A|108,108.30|\n",
      "| 1/11/1979|    220.7|135.9|   43,770.60|           #N/A|108,771.70|\n",
      "| 1/12/1979|    217.6|134.1|   42,837.10|           #N/A|106,856.60|\n",
      "| 1/15/1979|    216.9|133.8|   42,795.30|           #N/A|106,819.80|\n",
      "| 1/16/1979|    220.7|135.6|   43,225.90|           #N/A|107,689.80|\n",
      "| 1/17/1979|    227.3|139.2|   44,349.70|           #N/A|110,419.80|\n",
      "| 1/18/1979|    231.8|141.7|   44,823.40|           #N/A|111,599.20|\n",
      "| 1/19/1979|    230.6|141.1|   46,908.80|           #N/A|116,335.50|\n",
      "| 1/22/1979|      235|  144|   46,387.40|           #N/A|115,493.30|\n",
      "| 1/23/1979|      230|141.1|   45,633.10|           #N/A|113,615.30|\n",
      "| 1/24/1979|    236.1|144.7|   46,372.40|           #N/A|115,456.00|\n",
      "| 1/25/1979|    233.9|  144|   46,890.30|           #N/A|116,157.90|\n",
      "+----------+---------+-----+------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " cols=csvFile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "US_dollar\n",
      "Euro\n",
      "Japanese_yen\n",
      "Vietnamese_dong\n",
      "Korean_won\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "index =1\n",
    "while (index<len(cols)):\n",
    "    csvFile = csvFile.withColumn(cols[index], regexp_replace(cols[index], '#N/A', '0'))\n",
    "    csvFile = csvFile.withColumn(cols[index], regexp_replace(cols[index], ',', ''))\n",
    "    csvFile = csvFile.withColumn(cols[index], csvFile[cols[index]].cast('float'))\n",
    "    index=index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- US_dollar: float (nullable = true)\n",
      " |-- Euro: float (nullable = true)\n",
      " |-- Japanese_yen: float (nullable = true)\n",
      " |-- Vietnamese_dong: float (nullable = true)\n",
      " |-- Korean_won: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- US_dollar: float (nullable = true)\n",
      " |-- Euro: float (nullable = true)\n",
      " |-- Japanese_yen: float (nullable = true)\n",
      " |-- Vietnamese_dong: float (nullable = true)\n",
      " |-- Korean_won: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "\n",
    "# Setting an user define function:\n",
    "# This function converts the string cell into a date:\n",
    "func =  udf (lambda x: datetime.strptime(x, '%m/%d/%Y'), DateType())\n",
    "\n",
    "csvFile = csvFile.withColumn('Date', func(col('Date')))\n",
    "\n",
    "csvFile.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+------------+---------------+----------+\n",
      "|      Date|US_dollar| Euro|Japanese_yen|Vietnamese_dong|Korean_won|\n",
      "+----------+---------+-----+------------+---------------+----------+\n",
      "|1978-12-29|    226.0|137.1|         0.0|            0.0|       0.0|\n",
      "|1979-01-01|    226.0|137.1|         0.0|            0.0|       0.0|\n",
      "|1979-01-02|    226.8|137.3|     43164.9|            0.0|  107470.0|\n",
      "|1979-01-03|    218.6|134.0|     43717.9|            0.0|  108027.4|\n",
      "|1979-01-04|    223.2|136.8|     43674.9|            0.0|  108602.5|\n",
      "|1979-01-05|    225.5|138.4|     44582.5|            0.0|  110510.4|\n",
      "|1979-01-08|    223.1|136.4|     44436.2|            0.0|  110356.3|\n",
      "|1979-01-09|    224.0|137.3|     44045.6|            0.0|  109248.4|\n",
      "|1979-01-10|    220.7|135.5|     43366.4|            0.0|  108108.3|\n",
      "|1979-01-11|    220.7|135.9|     43770.6|            0.0|  108771.7|\n",
      "|1979-01-12|    217.6|134.1|     42837.1|            0.0|  106856.6|\n",
      "|1979-01-15|    216.9|133.8|     42795.3|            0.0|  106819.8|\n",
      "|1979-01-16|    220.7|135.6|     43225.9|            0.0|  107689.8|\n",
      "|1979-01-17|    227.3|139.2|     44349.7|            0.0|  110419.8|\n",
      "|1979-01-18|    231.8|141.7|     44823.4|            0.0|  111599.2|\n",
      "|1979-01-19|    230.6|141.1|     46908.8|            0.0|  116335.5|\n",
      "|1979-01-22|    235.0|144.0|     46387.4|            0.0|  115493.3|\n",
      "|1979-01-23|    230.0|141.1|     45633.1|            0.0|  113615.3|\n",
      "|1979-01-24|    236.1|144.7|     46372.4|            0.0|  115456.0|\n",
      "|1979-01-25|    233.9|144.0|     46890.3|            0.0|  116157.9|\n",
      "+----------+---------+-----+------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\")\\\n",
    ".save(\"hdfs://namenode:9000/gold/gold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
